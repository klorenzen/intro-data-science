<section xml:id="section-3-4">
	<title>Data Verbs in Python</title>
	<subsection><title>A bit more programming</title>
		<p>Today, we are going to get a bit more sophisticated in our programming skills. We will be focusing on <em>functions</em> and <em>loops.</em> 

A <term>function</term> is a recipe of directions that has inputs (ingredients) and an output (cake). Some functions are internally built into the object (like being able to measure flour) and others are external (like baking a cake). </p>

<p>Internal functions (sometimes called methods) happen after the variable name like so <c>flour.measure()</c> where <c>flour</c> is the variable name and <c>measure()</c> is a function that acts on <c>flour</c>. Sometimes things need to go into the parenthesis like what unit we can to measure in.<c>flour.measure("cups")</c>

This would not only measure the flour but do so in our desire unit, cups!</p>

<p>Other functions that are more like baking a cake have all their inputs in parenthesis. <c>
bake(flour, sugar, egg)
</c></p>


<p><term>Packages</term> are a special collection of functions that other people have written that we can use. To use a function from a package, we first have to import them into our notebook. 

Typical Packages:
<ul>
<li><p> Pandas - great for data, create a dataframe which has lots of neat features like our data verbs</p></li>
<li><p> NumPy - great for math like square roots. Has arrays which are nice for data manipulation</p></li>
<li><p> MatPlotLib.pyplots - MatLab-like plotting, basic visuals</p></li>
<li><p> Seaborn - more sophisticated plotting and making visuals</p></li>
<li><p> SkLearn - many algorithms and datasets for data analysis</p></li>
</ul>

When importing packages, you can either import the entire package or particular parts. All of these packages have documentation online (usually) with good examples of how to use their functions. 
</p>

<p>If a function comes from a package, then its name might include the package it came from.<c>
import pandas as pd
pd.read_csv(FILE_NAME)
</c>

Here <c>read_csv()</c> is a function from the <c>pandas</c> package which we named <c>pd</c>.

Load the pandas package and read the Titanic Dataset using the following URL: <c>URL="https://raw.githubusercontent.com/klorenzen/Data-Sets/main/titanic.csv"
</c></p>

<exercise xml:id="program-activecode-python">
      <title>Loading Data</title>
<program xml:id="python-load-data" interactive="activecode" language="python" label="load-data">
<input>
import pandas as pd
URL="https://raw.githubusercontent.com/klorenzen/Data-Sets/main/titanic.csv"
pd.read_csv(URL)
</input>
</program>
    </exercise>
</subsection>

<subsection><title>Data Verbs</title>

	<p><ul>
		<li><p>To <term>select</term> a particular column from our data set we would write:<c>df[ColumnName]</c>. If we have multiple columns, we need to give write a list of all the column names we need (or splice from the <c>df.columns</c> list). There are other ways to do this, but this is one of the more direct ways. For the titanic dataset, select the <c>survived</c>, <c>age</c>, and <c>boat</c> columns.</p></li>

		<li><p>To <term>filter</term> particular rows based on a logical expression (think ==, >, .isin(), etc) we would write:<c>df[df[ColumnName]=="Pugs"]</c> If we had multiple filters or wanted to do filtering at the same time as selecting we would need to write:<c>df.loc[(FILTER 1) &amp; (FILTER 2), [ColumnName1, ColumnName2]]</c> where the `&amp;` acts like `and` for our logical expressions. For the titanic dataset, select the <c>survived</c>, <c>age</c>, and <c>boat</c> columns and filter the dataset so we only have <c>female</c> passengers.</p></li>

		<li><p>To make a new column based on previous columns (<term>mutate</term>) we will do an assignment for our new columns as follows:<c>df[NewColumn]=Stuff with previous columns</c> How we get the stuff with previous columns is always interesting! For the Titanic dataset, create a new column that is just the cabin letter for the passengers who have a cabin entry.</p></li>

		<li><p>To <term>sort</term> by particular column(s) we would write: <c>df.sort_values(by=Columns, ascending=True)</c> It will automatically go from smallest to biggest, to go the other way we will need to change `ascending` to `False`. For the Titanic dataset, find who the youngest person was on the ship and who was the oldest.</p></li>

		<li><p> <term>Grouping</term> breaks our dataset into many little pieces so we can study it by subgroup. We would write: <c>df.groupby([Column1, Column2])</c> Grouping is almost always used with aggregate which applies a function over a column.</p></li>

		<li><p> <term>Aggregate</term> applies a function over an entire column (or portion of column if grouped first). We would write: <c> df.agg(['sum', 'min', 'max', 'mean'])</c> or <c>df.agg({'Column1':['sum', 'mean'], 'Column2':['min', 'max']})</c> You can also pass it functions you wrote yourself! For the Titanic dataset, find the average age of people who survived and the average age of people who did not survive. How does compare to the average age of female/male passengers?</p></li>

	</ul></p>



</subsection>


</section>